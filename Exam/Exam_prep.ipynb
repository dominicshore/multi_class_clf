{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "raw_dataset = load_breast_cancer()\n",
    "raw_X = raw_dataset['data']\n",
    "raw_y = raw_dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_X.shape, raw_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_norm = MinMaxScaler()\n",
    "target_1hot = OneHotEncoder()\n",
    "X = feat_norm.fit_transform(raw_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = raw_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.620776</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606901</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556386</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248310</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519744</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.428813</td>\n",
       "      <td>0.678668</td>\n",
       "      <td>0.566490</td>\n",
       "      <td>0.526948</td>\n",
       "      <td>0.296055</td>\n",
       "      <td>0.571462</td>\n",
       "      <td>0.690358</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.132056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623266</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>0.576174</td>\n",
       "      <td>0.452664</td>\n",
       "      <td>0.461137</td>\n",
       "      <td>0.178527</td>\n",
       "      <td>0.328035</td>\n",
       "      <td>0.761512</td>\n",
       "      <td>0.097575</td>\n",
       "      <td>0.105667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.622320</td>\n",
       "      <td>0.626987</td>\n",
       "      <td>0.604036</td>\n",
       "      <td>0.474019</td>\n",
       "      <td>0.407782</td>\n",
       "      <td>0.257714</td>\n",
       "      <td>0.337395</td>\n",
       "      <td>0.486630</td>\n",
       "      <td>0.349495</td>\n",
       "      <td>0.113100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560655</td>\n",
       "      <td>0.699094</td>\n",
       "      <td>0.520892</td>\n",
       "      <td>0.379915</td>\n",
       "      <td>0.300007</td>\n",
       "      <td>0.159997</td>\n",
       "      <td>0.256789</td>\n",
       "      <td>0.559450</td>\n",
       "      <td>0.198502</td>\n",
       "      <td>0.074315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.455251</td>\n",
       "      <td>0.621238</td>\n",
       "      <td>0.445788</td>\n",
       "      <td>0.303118</td>\n",
       "      <td>0.288165</td>\n",
       "      <td>0.254340</td>\n",
       "      <td>0.216753</td>\n",
       "      <td>0.263519</td>\n",
       "      <td>0.267677</td>\n",
       "      <td>0.137321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393099</td>\n",
       "      <td>0.589019</td>\n",
       "      <td>0.379949</td>\n",
       "      <td>0.230731</td>\n",
       "      <td>0.282177</td>\n",
       "      <td>0.273705</td>\n",
       "      <td>0.271805</td>\n",
       "      <td>0.487285</td>\n",
       "      <td>0.128721</td>\n",
       "      <td>0.151909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.663510</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.475716</td>\n",
       "      <td>0.588336</td>\n",
       "      <td>0.790197</td>\n",
       "      <td>0.823336</td>\n",
       "      <td>0.755467</td>\n",
       "      <td>0.675253</td>\n",
       "      <td>0.425442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633582</td>\n",
       "      <td>0.730277</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.402035</td>\n",
       "      <td>0.619626</td>\n",
       "      <td>0.815758</td>\n",
       "      <td>0.749760</td>\n",
       "      <td>0.910653</td>\n",
       "      <td>0.497142</td>\n",
       "      <td>0.452315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.036869</td>\n",
       "      <td>0.501522</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266162</td>\n",
       "      <td>0.187026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054287</td>\n",
       "      <td>0.489072</td>\n",
       "      <td>0.043578</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>0.124084</td>\n",
       "      <td>0.036043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257441</td>\n",
       "      <td>0.100682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0       0.521037      0.022658        0.545989   0.363733         0.593753   \n",
       "1       0.643144      0.272574        0.615783   0.501591         0.289880   \n",
       "2       0.601496      0.390260        0.595743   0.449417         0.514309   \n",
       "3       0.210090      0.360839        0.233501   0.102906         0.811321   \n",
       "4       0.629893      0.156578        0.630986   0.489290         0.430351   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564     0.690000      0.428813        0.678668   0.566490         0.526948   \n",
       "565     0.622320      0.626987        0.604036   0.474019         0.407782   \n",
       "566     0.455251      0.621238        0.445788   0.303118         0.288165   \n",
       "567     0.644564      0.663510        0.665538   0.475716         0.588336   \n",
       "568     0.036869      0.501522        0.028540   0.015907         0.000000   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0            0.792037        0.703140             0.731113       0.686364   \n",
       "1            0.181768        0.203608             0.348757       0.379798   \n",
       "2            0.431017        0.462512             0.635686       0.509596   \n",
       "3            0.811361        0.565604             0.522863       0.776263   \n",
       "4            0.347893        0.463918             0.518390       0.378283   \n",
       "..                ...             ...                  ...            ...   \n",
       "564          0.296055        0.571462             0.690358       0.336364   \n",
       "565          0.257714        0.337395             0.486630       0.349495   \n",
       "566          0.254340        0.216753             0.263519       0.267677   \n",
       "567          0.790197        0.823336             0.755467       0.675253   \n",
       "568          0.074351        0.000000             0.000000       0.266162   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                  0.605518  ...      0.620776       0.141525   \n",
       "1                  0.141323  ...      0.606901       0.303571   \n",
       "2                  0.211247  ...      0.556386       0.360075   \n",
       "3                  1.000000  ...      0.248310       0.385928   \n",
       "4                  0.186816  ...      0.519744       0.123934   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                0.132056  ...      0.623266       0.383262   \n",
       "565                0.113100  ...      0.560655       0.699094   \n",
       "566                0.137321  ...      0.393099       0.589019   \n",
       "567                0.425442  ...      0.633582       0.730277   \n",
       "568                0.187026  ...      0.054287       0.489072   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0           0.668310    0.450698          0.601136           0.619292   \n",
       "1           0.539818    0.435214          0.347553           0.154563   \n",
       "2           0.508442    0.374508          0.483590           0.385375   \n",
       "3           0.241347    0.094008          0.915472           0.814012   \n",
       "4           0.506948    0.341575          0.437364           0.172415   \n",
       "..               ...         ...               ...                ...   \n",
       "564         0.576174    0.452664          0.461137           0.178527   \n",
       "565         0.520892    0.379915          0.300007           0.159997   \n",
       "566         0.379949    0.230731          0.282177           0.273705   \n",
       "567         0.668310    0.402035          0.619626           0.815758   \n",
       "568         0.043578    0.020497          0.124084           0.036043   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0           0.568610              0.912027        0.598462   \n",
       "1           0.192971              0.639175        0.233590   \n",
       "2           0.359744              0.835052        0.403706   \n",
       "3           0.548642              0.884880        1.000000   \n",
       "4           0.319489              0.558419        0.157500   \n",
       "..               ...                   ...             ...   \n",
       "564         0.328035              0.761512        0.097575   \n",
       "565         0.256789              0.559450        0.198502   \n",
       "566         0.271805              0.487285        0.128721   \n",
       "567         0.749760              0.910653        0.497142   \n",
       "568         0.000000              0.000000        0.257441   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                   0.418864  \n",
       "1                   0.222878  \n",
       "2                   0.213433  \n",
       "3                   0.773711  \n",
       "4                   0.142595  \n",
       "..                       ...  \n",
       "564                 0.105667  \n",
       "565                 0.074315  \n",
       "566                 0.151909  \n",
       "567                 0.452315  \n",
       "568                 0.100682  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X, columns = raw_dataset['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) (569,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_clf(unit=5, optim='adam'):\n",
    "  # creating the layers of the NN\n",
    "  ann = tf.keras.models.Sequential()\n",
    "  ann.add(tf.keras.layers.Dense(units=unit, activation='relu'))\n",
    "  ann.add(tf.keras.layers.Dense(units=unit, activation='relu'))\n",
    "  ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "  ann.compile(optimizer = optim, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dominic\\AppData\\Local\\Temp\\ipykernel_11248\\4191736314.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=build_clf)\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=build_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'unit': [5, 20, 15, 20], 'optim': ['adam', 'SGD']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7069 - accuracy: 0.4081\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 0.7140 - accuracy: 0.3043\n",
      "9/9 [==============================] - 0s 963us/step - loss: 0.7026 - accuracy: 0.4081\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7130 - accuracy: 0.3736\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.4412\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7051 - accuracy: 0.3773\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6654 - accuracy: 0.3993\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6705 - accuracy: 0.3971\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.6603 - accuracy: 0.4176\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.6081\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6971 - accuracy: 0.6029\n",
      "9/9 [==============================] - 0s 936us/step - loss: 0.6869 - accuracy: 0.6410\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7062 - accuracy: 0.6081\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.6324\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6981 - accuracy: 0.6044\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.4118\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.3188\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6812 - accuracy: 0.4118\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6729 - accuracy: 0.6886\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6667 - accuracy: 0.7353\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6606 - accuracy: 0.7546\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7160 - accuracy: 0.5055\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6978 - accuracy: 0.6324\n",
      "9/9 [==============================] - 0s 876us/step - loss: 0.7031 - accuracy: 0.6007\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6978 - accuracy: 0.3773\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6711 - accuracy: 0.5000\n",
      "9/9 [==============================] - 0s 879us/step - loss: 0.6848 - accuracy: 0.3956\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6766 - accuracy: 0.6117\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6693 - accuracy: 0.6324\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6647 - accuracy: 0.6227\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.5919\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6683 - accuracy: 0.6957\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6693 - accuracy: 0.5919\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5678\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6905 - accuracy: 0.5588\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.6410\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6740 - accuracy: 0.4029\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.3971\n",
      "9/9 [==============================] - 0s 878us/step - loss: 0.6652 - accuracy: 0.4249\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.6337\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.7005 - accuracy: 0.5294\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6734 - accuracy: 0.6337\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6846 - accuracy: 0.6557\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 0.6793 - accuracy: 0.7059\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6781 - accuracy: 0.6996\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5294\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6793 - accuracy: 0.6522\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.6287\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6836 - accuracy: 0.4396\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6654 - accuracy: 0.5882\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6715 - accuracy: 0.5897\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7026 - accuracy: 0.4139\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.4412\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.6871 - accuracy: 0.4322\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6678 - accuracy: 0.7033\n",
      "3/3 [==============================] - 0s 998us/step - loss: 0.6483 - accuracy: 0.8088\n",
      "9/9 [==============================] - 0s 875us/step - loss: 0.6512 - accuracy: 0.7802\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6655 - accuracy: 0.8278\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.8824\n",
      "9/9 [==============================] - 0s 875us/step - loss: 0.6509 - accuracy: 0.9158\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7012 - accuracy: 0.5699\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.6957\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.6991 - accuracy: 0.5919\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6968 - accuracy: 0.4322\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5294\n",
      "9/9 [==============================] - 0s 885us/step - loss: 0.6937 - accuracy: 0.5238\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5788\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5882\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5714\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6747 - accuracy: 0.4066\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6388 - accuracy: 0.4706\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.6697 - accuracy: 0.4249\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7307 - accuracy: 0.3846\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.7274 - accuracy: 0.3529\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7261 - accuracy: 0.3956\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4154\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.3333\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.4338\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.4066\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6798 - accuracy: 0.5147\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.4652\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5788\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6878 - accuracy: 0.5882\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6833 - accuracy: 0.6337\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.3700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6601 - accuracy: 0.4853\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.3700\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7078 - accuracy: 0.4176\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7034 - accuracy: 0.4118\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7028 - accuracy: 0.4652\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.7006 - accuracy: 0.5625\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.6957\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6959 - accuracy: 0.5772\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.6300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6784 - accuracy: 0.5735\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6776 - accuracy: 0.6264\n",
      "9/9 [==============================] - 1s 1ms/step - loss: 0.6974 - accuracy: 0.6044\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.6471\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6966 - accuracy: 0.6044\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6920 - accuracy: 0.6337\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7096 - accuracy: 0.5294\n",
      "9/9 [==============================] - 0s 875us/step - loss: 0.6905 - accuracy: 0.6337\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.6117\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6841 - accuracy: 0.6324\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.6117\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.4559\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4058\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6845 - accuracy: 0.4963\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.7068 - accuracy: 0.3736\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.4412\n",
      "9/9 [==============================] - 0s 987us/step - loss: 0.7032 - accuracy: 0.3736\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7033 - accuracy: 0.6044\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6763 - accuracy: 0.6471\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 0.6987 - accuracy: 0.6044\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6859 - accuracy: 0.6520\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6841 - accuracy: 0.5882\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.6630\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6987 - accuracy: 0.5495\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7011 - accuracy: 0.5735\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6967 - accuracy: 0.5751\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5924\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x000001194D972650&gt;,\n",
       "             param_grid={&#x27;bonker&#x27;: [&#x27;adam&#x27;, &#x27;SGD&#x27;], &#x27;unit&#x27;: [5, 20, 15, 20]},\n",
       "             return_train_score=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x000001194D972650&gt;,\n",
       "             param_grid={&#x27;bonker&#x27;: [&#x27;adam&#x27;, &#x27;SGD&#x27;], &#x27;unit&#x27;: [5, 20, 15, 20]},\n",
       "             return_train_score=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x000001194D972650&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x000001194D972650&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x000001194D972650>,\n",
       "             param_grid={'bonker': ['adam', 'SGD'], 'unit': [5, 20, 15, 20]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params=grid_search.best_params_\n",
    "accuracy=grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonker': 'adam', 'unit': 20}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6745524406433105"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96f48c9e96326d159497092596a842df84442ffbf742d0c9b5922831fba25b6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
